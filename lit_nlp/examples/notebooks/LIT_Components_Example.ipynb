{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LIT Components Example",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2c6PyqQaNiA"
      },
      "source": [
        "# LIT Standalone Components\n",
        "\n",
        "This notebook shows use of the [Learning Interpretability Tool](https://pair-code.github.io/lit) components on a binary classifier for labelling statement sentiment (0 for negative, 1 for positive).\n",
        "\n",
        "All LIT backend components (models, datasets, metrics, generators, etc.) are standalone Python classes, and can easily be used from Colab or another Python context without starting a server. This can be handy for development, of if you want to re-use components in an offline workflow.\n",
        "\n",
        "Copyright 2021 Google LLC.\n",
        "SPDX-License-Identifier: Apache-2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukXamAB_FBM8"
      },
      "source": [
        "# Install LIT and transformers packages. The transformers package is needed by the model and dataset we are using.\n",
        "# Replace tensorflow-datasets with the nightly package to get up-to-date dataset paths.\n",
        "!pip uninstall -y tensorflow-datasets\n",
        "!pip install lit_nlp tfds-nightly transformers==4.1.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x38BqRdJFlyW"
      },
      "source": [
        "## Load data\n",
        "\n",
        "LIT's `Dataset` classes are just lists of records, plus spec information to describe each field."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWhbAZg57RpB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f34dc6b4-9fe4-4d00-f987-a7660b96cd15"
      },
      "source": [
        "import attr\n",
        "import pandas as pd\n",
        "\n",
        "from lit_nlp import notebook\n",
        "from lit_nlp.examples.datasets import glue\n",
        "from lit_nlp.examples.models import glue_models\n",
        "\n",
        "sst_data = glue.SST2Data('validation')\n",
        "sst_data.spec()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/glue/sst2/2.0.0\n",
            "INFO:absl:Reusing dataset glue (/root/tensorflow_datasets/glue/sst2/2.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset glue for split validation, from /root/tensorflow_datasets/glue/sst2/2.0.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': CategoryLabel(required=True, vocab=['0', '1']),\n",
              " 'sentence': TextSegment(required=True, default='')}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GSfs1waBdLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcbb376d-dab5-4bae-b4f0-191643683c4a"
      },
      "source": [
        "sst_data.examples[:10]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': '1', 'sentence': \"it 's a charming and often affecting journey . \"},\n",
              " {'label': '0', 'sentence': 'unflinchingly bleak and desperate '},\n",
              " {'label': '1',\n",
              "  'sentence': 'allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker . '},\n",
              " {'label': '1',\n",
              "  'sentence': \"the acting , costumes , music , cinematography and sound are all astounding given the production 's austere locales . \"},\n",
              " {'label': '0', 'sentence': \"it 's slow -- very , very slow . \"},\n",
              " {'label': '1',\n",
              "  'sentence': 'although laced with humor and a few fanciful touches , the film is a refreshingly serious look at young women . '},\n",
              " {'label': '0', 'sentence': 'a sometimes tedious film . '},\n",
              " {'label': '0',\n",
              "  'sentence': \"or doing last year 's taxes with your ex-wife . \"},\n",
              " {'label': '1',\n",
              "  'sentence': \"you do n't have to know about music to appreciate the film 's easygoing blend of comedy and romance . \"},\n",
              " {'label': '0',\n",
              "  'sentence': \"in exactly 89 minutes , most of which passed as slowly as if i 'd been sitting naked on an igloo , formula 51 sank from quirky to jerky to utter turkey . \"}]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_hlS2eAFtxu"
      },
      "source": [
        "You can easily convert this to tabular form, too:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "fW6GyeJ8FrkB",
        "outputId": "2f397e2b-9eb6-417d-9c90-738c3bfb7c05"
      },
      "source": [
        "pd.DataFrame(sst_data.examples)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>it 's a charming and often affecting journey .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>unflinchingly bleak and desperate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>allows us to hope that nolan is poised to emba...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the acting , costumes , music , cinematography...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>it 's slow -- very , very slow .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>867</th>\n",
              "      <td>has all the depth of a wading pool .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>868</th>\n",
              "      <td>a movie with a real anarchic flair .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>869</th>\n",
              "      <td>a subject like this should inspire reaction in...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>870</th>\n",
              "      <td>... is an arthritic attempt at directing by ca...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>871</th>\n",
              "      <td>looking aristocratic , luminous yet careworn i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>872 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              sentence label\n",
              "0      it 's a charming and often affecting journey .      1\n",
              "1                   unflinchingly bleak and desperate      0\n",
              "2    allows us to hope that nolan is poised to emba...     1\n",
              "3    the acting , costumes , music , cinematography...     1\n",
              "4                    it 's slow -- very , very slow .      0\n",
              "..                                                 ...   ...\n",
              "867              has all the depth of a wading pool .      0\n",
              "868              a movie with a real anarchic flair .      1\n",
              "869  a subject like this should inspire reaction in...     0\n",
              "870  ... is an arthritic attempt at directing by ca...     0\n",
              "871  looking aristocratic , luminous yet careworn i...     1\n",
              "\n",
              "[872 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZeDs3bOFygS"
      },
      "source": [
        "## Load a model and run inference\n",
        "\n",
        "LIT's `Model` class defines a `predict()` function to perform inference. The `input_spec()` describes the expected inputs (it should be a subset of the dataset fields), and `output_spec()` describes the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30l9ZyTjxJjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda76ba1-a403-4f5a-e753-18dddef50107"
      },
      "source": [
        "# Fetch the trained model weights and load the model to analyze\n",
        "!wget https://storage.googleapis.com/what-if-tool-resources/lit-models/sst2_tiny.tar.gz\n",
        "!mkdir sst2_tiny\n",
        "!tar -xvf sst2_tiny.tar.gz -C sst2_tiny\n",
        "\n",
        "sentiment_model = glue_models.SST2Model('./sst2_tiny')\n",
        "sentiment_model.input_spec(), sentiment_model.output_spec()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-14 14:15:38--  https://storage.googleapis.com/what-if-tool-resources/lit-models/sst2_tiny.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 74.125.197.128, 74.125.142.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16362834 (16M) [application/octet-stream]\n",
            "Saving to: â€˜sst2_tiny.tar.gz.1â€™\n",
            "\n",
            "sst2_tiny.tar.gz.1  100%[===================>]  15.60M  81.4MB/s    in 0.2s    \n",
            "\n",
            "2021-10-14 14:15:38 (81.4 MB/s) - â€˜sst2_tiny.tar.gz.1â€™ saved [16362834/16362834]\n",
            "\n",
            "./\n",
            "./tokenizer_config.json\n",
            "./tf_model.h5\n",
            "./config.json\n",
            "./train.history.json\n",
            "./vocab.txt\n",
            "./special_tokens_map.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at ./.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'grad_class': CategoryLabel(required=False, vocab=['0', '1']),\n",
              "  'input_embs_sentence': TokenEmbeddings(required=False, align='tokens'),\n",
              "  'label': CategoryLabel(required=False, vocab=['0', '1']),\n",
              "  'sentence': TextSegment(required=True, default=''),\n",
              "  'tokens_sentence': Tokens(required=False, default=[], parent='sentence', mask_token=None)},\n",
              " {'cls_emb': Embeddings(required=True),\n",
              "  'cls_grad': Gradients(required=True, grad_for='cls_emb', grad_target_field_key='grad_class'),\n",
              "  'grad_class': CategoryLabel(required=False, vocab=['0', '1']),\n",
              "  'input_embs_sentence': TokenEmbeddings(required=True, align='tokens_sentence'),\n",
              "  'layer_0/attention': AttentionHeads(required=True, align_in='tokens', align_out='tokens'),\n",
              "  'layer_1/attention': AttentionHeads(required=True, align_in='tokens', align_out='tokens'),\n",
              "  'probas': MulticlassPreds(required=True, vocab=['0', '1'], null_idx=0, parent='label'),\n",
              "  'token_grad_sentence': TokenGradients(required=True, align='tokens_sentence', grad_for='input_embs_sentence', grad_target_field_key='grad_class'),\n",
              "  'tokens': Tokens(required=True, default=[], parent=None, mask_token=None),\n",
              "  'tokens_sentence': Tokens(required=True, default=[], parent='sentence', mask_token=None)})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKcqVijmGPLH"
      },
      "source": [
        "There's a lot of fields in the output spec, since this model returns embeddings, gradients, attention, and more. We can view it using Pandas to avoid too much clutter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "-KdWHCUHGP4o",
        "outputId": "2a16ae42-51a1-4285-ddae-21bb2b704fa9"
      },
      "source": [
        "preds = list(sentiment_model.predict(sst_data.examples[:10]))\n",
        "pd.DataFrame(preds)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cls_emb</th>\n",
              "      <th>input_embs</th>\n",
              "      <th>layer_0/attention</th>\n",
              "      <th>layer_1/attention</th>\n",
              "      <th>probas</th>\n",
              "      <th>grad_class</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tokens_sentence</th>\n",
              "      <th>input_embs_sentence</th>\n",
              "      <th>token_grad_sentence</th>\n",
              "      <th>cls_grad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.004583381, -0.35583165, -1.0134914, 1.5898,...</td>\n",
              "      <td>[[0.017338583, -0.016962294, -0.501561, -0.010...</td>\n",
              "      <td>[[[0.31375167, 0.21949047, 0.57060295, 0.51083...</td>\n",
              "      <td>[[[0.08148516, 0.821547, 0.3571193, 0.4449412,...</td>\n",
              "      <td>[0.008859163, 0.9911409]</td>\n",
              "      <td>1</td>\n",
              "      <td>[[CLS], it, ', s, a, charming, and, often, aff...</td>\n",
              "      <td>[it, ', s, a, charming, and, often, affecting,...</td>\n",
              "      <td>[[-0.02315473, 0.028583972, -0.043904603, -0.0...</td>\n",
              "      <td>[[-7.5466356e-05, -0.000115628325, 0.000267486...</td>\n",
              "      <td>[0.00018687929, 4.704453e-05, 4.0064948e-05, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-0.53348106, -1.2959056, -2.0872705, -1.42752...</td>\n",
              "      <td>[[0.017338583, -0.016962294, -0.501561, -0.010...</td>\n",
              "      <td>[[[0.2999308, 0.019363625, 0.012921629, 0.0961...</td>\n",
              "      <td>[[[0.07893149, 0.9353795, 0.3541118, 0.8020245...</td>\n",
              "      <td>[0.8705278, 0.12947221]</td>\n",
              "      <td>0</td>\n",
              "      <td>[[CLS], un, ##fl, ##in, ##ching, ##ly, bleak, ...</td>\n",
              "      <td>[un, ##fl, ##in, ##ching, ##ly, bleak, and, de...</td>\n",
              "      <td>[[-0.037998863, -0.024275642, 0.061621126, -0....</td>\n",
              "      <td>[[0.051445995, 0.044628385, -0.19452904, 0.001...</td>\n",
              "      <td>[-0.03781466, 0.00041138422, 0.002508022, 0.08...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0.3407998, 0.20537995, -1.5944655, 1.2758317,...</td>\n",
              "      <td>[[0.017338583, -0.016962294, -0.501561, -0.010...</td>\n",
              "      <td>[[[0.14481069, 0.044249136, 0.13230227, 0.7652...</td>\n",
              "      <td>[[[0.02976306, 0.69763637, 0.8893215, 0.930776...</td>\n",
              "      <td>[0.011394653, 0.9886053]</td>\n",
              "      <td>1</td>\n",
              "      <td>[[CLS], allows, us, to, hope, that, nolan, is,...</td>\n",
              "      <td>[allows, us, to, hope, that, nolan, is, poised...</td>\n",
              "      <td>[[-0.004202644, 0.065549225, -0.06381365, 0.01...</td>\n",
              "      <td>[[-0.0014428259, -0.00046781698, 0.0026154125,...</td>\n",
              "      <td>[0.00020122774, -0.0011052014, -0.00013908498,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0.9169466, 0.90732324, -2.097221, 0.38243675,...</td>\n",
              "      <td>[[0.017338583, -0.016962294, -0.501561, -0.010...</td>\n",
              "      <td>[[[0.1122977, 0.47727907, 0.08321068, 0.502560...</td>\n",
              "      <td>[[[0.028648494, 0.8274244, 0.6397511, 0.897796...</td>\n",
              "      <td>[0.032677714, 0.9673223]</td>\n",
              "      <td>1</td>\n",
              "      <td>[[CLS], the, acting, ,, costumes, ,, music, ,,...</td>\n",
              "      <td>[the, acting, ,, costumes, ,, music, ,, cinema...</td>\n",
              "      <td>[[-0.043320682, 0.02815245, -0.027521769, -0.0...</td>\n",
              "      <td>[[-0.00048740115, -0.004126699, 0.006568273, 0...</td>\n",
              "      <td>[-0.012909396, -0.014266191, 0.00075534085, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-0.64637935, 0.06891413, -1.4176737, -1.76827...</td>\n",
              "      <td>[[0.017338583, -0.016962294, -0.501561, -0.010...</td>\n",
              "      <td>[[[0.30667877, 0.22150387, 0.55423075, 0.45006...</td>\n",
              "      <td>[[[0.034146205, 0.47710592, 0.15084067, 0.1739...</td>\n",
              "      <td>[0.97357225, 0.026427716]</td>\n",
              "      <td>0</td>\n",
              "      <td>[[CLS], it, ', s, slow, -, -, very, ,, very, s...</td>\n",
              "      <td>[it, ', s, slow, -, -, very, ,, very, slow, .]</td>\n",
              "      <td>[[-0.02315473, 0.028583972, -0.043904603, -0.0...</td>\n",
              "      <td>[[0.00035544863, -0.00032099197, 0.00066477346...</td>\n",
              "      <td>[-0.0020571523, -0.0006151155, 0.0007737565, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[0.27590856, -1.0817645, -0.84292084, 1.259297...</td>\n",
              "      <td>[[0.017338583, -0.016962294, -0.501561, -0.010...</td>\n",
              "      <td>[[[0.1573781, 0.21759886, 0.011105451, 0.49348...</td>\n",
              "      <td>[[[0.016249932, 0.8166377, 0.3254434, 0.557768...</td>\n",
              "      <td>[0.00933072, 0.99066925]</td>\n",
              "      <td>1</td>\n",
              "      <td>[[CLS], although, laced, with, humor, and, a, ...</td>\n",
              "      <td>[although, laced, with, humor, and, a, few, fa...</td>\n",
              "      <td>[[0.03739236, 0.031962592, -0.045048732, -0.02...</td>\n",
              "      <td>[[-4.4891396e-05, -0.00037057052, 0.0008015726...</td>\n",
              "      <td>[-0.00010475758, -8.198748e-05, -2.4683137e-05...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[-0.7365836, -0.32791507, -1.1239178, -2.5176,...</td>\n",
              "      <td>[[0.017338583, -0.016962294, -0.501561, -0.010...</td>\n",
              "      <td>[[[0.3160024, 0.80639344, 0.27915937, 0.002850...</td>\n",
              "      <td>[[[0.062158547, 0.6758493, 0.49058425, 0.65609...</td>\n",
              "      <td>[0.92046547, 0.07953453]</td>\n",
              "      <td>0</td>\n",
              "      <td>[[CLS], a, sometimes, ted, ##ious, film, ., [S...</td>\n",
              "      <td>[a, sometimes, ted, ##ious, film, .]</td>\n",
              "      <td>[[-0.04020428, -0.0076383823, -0.00210628, -0....</td>\n",
              "      <td>[[0.015292119, 0.0066954284, -0.027800344, 0.0...</td>\n",
              "      <td>[0.0010592741, 0.021598997, 0.0141387, 0.16900...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[0.5832945, 0.63631034, -2.8385923, -1.4457783...</td>\n",
              "      <td>[[0.017338583, -0.016962294, -0.501561, -0.010...</td>\n",
              "      <td>[[[0.25043583, 0.26420912, 0.12593256, 0.53413...</td>\n",
              "      <td>[[[0.06434139, 0.82461584, 0.6095685, 0.728478...</td>\n",
              "      <td>[0.81982076, 0.18017924]</td>\n",
              "      <td>0</td>\n",
              "      <td>[[CLS], or, doing, last, year, ', s, taxes, wi...</td>\n",
              "      <td>[or, doing, last, year, ', s, taxes, with, you...</td>\n",
              "      <td>[[0.013928796, -0.019496849, 0.0027626788, -0....</td>\n",
              "      <td>[[0.050629728, -0.0065926146, -0.21742009, 0.0...</td>\n",
              "      <td>[-0.01321427, -0.006679442, -0.0098229265, 0.2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[0.52883273, -0.21691558, -1.4896792, 0.849138...</td>\n",
              "      <td>[[0.017338583, -0.016962294, -0.501561, -0.010...</td>\n",
              "      <td>[[[0.14710318, 0.19424808, 0.21983576, 0.10918...</td>\n",
              "      <td>[[[0.01758575, 0.9006142, 0.928713, 0.36878332...</td>\n",
              "      <td>[0.012007768, 0.98799217]</td>\n",
              "      <td>1</td>\n",
              "      <td>[[CLS], you, do, n, ', t, have, to, know, abou...</td>\n",
              "      <td>[you, do, n, ', t, have, to, know, about, musi...</td>\n",
              "      <td>[[0.037536107, 0.020549815, 0.021361152, -0.02...</td>\n",
              "      <td>[[-0.00086325133, -9.273212e-05, -0.0009672394...</td>\n",
              "      <td>[0.00059932854, -0.00019684795, 0.0007904038, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[-0.5880315, -0.18577582, -2.6173072, -1.18181...</td>\n",
              "      <td>[[0.017338583, -0.016962294, -0.501561, -0.010...</td>\n",
              "      <td>[[[0.0858297, 0.45183423, 0.027695835, 0.24190...</td>\n",
              "      <td>[[[0.008476875, 0.8329102, 0.44881406, 0.16382...</td>\n",
              "      <td>[0.9704254, 0.0295746]</td>\n",
              "      <td>0</td>\n",
              "      <td>[[CLS], in, exactly, 89, minutes, ,, most, of,...</td>\n",
              "      <td>[in, exactly, 89, minutes, ,, most, of, which,...</td>\n",
              "      <td>[[-0.011132047, -0.0225919, -0.065105245, -0.2...</td>\n",
              "      <td>[[0.0034596722, -6.9231464e-06, 0.0036073057, ...</td>\n",
              "      <td>[-0.0029212034, 0.0008398305, -0.0032024528, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             cls_emb  ...                                           cls_grad\n",
              "0  [0.004583381, -0.35583165, -1.0134914, 1.5898,...  ...  [0.00018687929, 4.704453e-05, 4.0064948e-05, -...\n",
              "1  [-0.53348106, -1.2959056, -2.0872705, -1.42752...  ...  [-0.03781466, 0.00041138422, 0.002508022, 0.08...\n",
              "2  [0.3407998, 0.20537995, -1.5944655, 1.2758317,...  ...  [0.00020122774, -0.0011052014, -0.00013908498,...\n",
              "3  [0.9169466, 0.90732324, -2.097221, 0.38243675,...  ...  [-0.012909396, -0.014266191, 0.00075534085, 0....\n",
              "4  [-0.64637935, 0.06891413, -1.4176737, -1.76827...  ...  [-0.0020571523, -0.0006151155, 0.0007737565, 0...\n",
              "5  [0.27590856, -1.0817645, -0.84292084, 1.259297...  ...  [-0.00010475758, -8.198748e-05, -2.4683137e-05...\n",
              "6  [-0.7365836, -0.32791507, -1.1239178, -2.5176,...  ...  [0.0010592741, 0.021598997, 0.0141387, 0.16900...\n",
              "7  [0.5832945, 0.63631034, -2.8385923, -1.4457783...  ...  [-0.01321427, -0.006679442, -0.0098229265, 0.2...\n",
              "8  [0.52883273, -0.21691558, -1.4896792, 0.849138...  ...  [0.00059932854, -0.00019684795, 0.0007904038, ...\n",
              "9  [-0.5880315, -0.18577582, -2.6173072, -1.18181...  ...  [-0.0029212034, 0.0008398305, -0.0032024528, 0...\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf_cufk9GXRp"
      },
      "source": [
        "If we just want the predicted probabilites for each class, we can look at the `probas` field:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "ZppG2HSrGXyc",
        "outputId": "560714fb-f43c-434e-b226-792e9d04b2de"
      },
      "source": [
        "labels = sentiment_model.output_spec()['probas'].vocab\n",
        "pd.DataFrame([p['probas'] for p in preds], columns=pd.Index(labels, name='label'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>label</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.008859</td>\n",
              "      <td>0.991141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.870528</td>\n",
              "      <td>0.129472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.011395</td>\n",
              "      <td>0.988605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.032678</td>\n",
              "      <td>0.967322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.973572</td>\n",
              "      <td>0.026428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.009331</td>\n",
              "      <td>0.990669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.920465</td>\n",
              "      <td>0.079535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.819821</td>\n",
              "      <td>0.180179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.012008</td>\n",
              "      <td>0.987992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.970425</td>\n",
              "      <td>0.029575</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "label         0         1\n",
              "0      0.008859  0.991141\n",
              "1      0.870528  0.129472\n",
              "2      0.011395  0.988605\n",
              "3      0.032678  0.967322\n",
              "4      0.973572  0.026428\n",
              "5      0.009331  0.990669\n",
              "6      0.920465  0.079535\n",
              "7      0.819821  0.180179\n",
              "8      0.012008  0.987992\n",
              "9      0.970425  0.029575"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "555KTfI8GcHN"
      },
      "source": [
        "## Salience methods\n",
        "\n",
        "We can use different interpretability components as well. Here's an example running LIME to get a salience map. The output has entries for each input field, though here that's just one field named \"sentence\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iW42OVpGcme",
        "outputId": "4dd41374-18d0-4f0e-c813-d91a1667aad2"
      },
      "source": [
        "from lit_nlp.components import lime_explainer\n",
        "lime = lime_explainer.LIME()\n",
        "\n",
        "lime_results = lime.run(sst_data.examples[:1], sentiment_model, sst_data)[0]\n",
        "lime_results"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Found text fields for LIME attribution: ['sentence']\n",
            "INFO:absl:Explaining: it 's a charming and often affecting journey . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence': TokenSalience(tokens=['it', \"'s\", 'a', 'charming', 'and', 'often', 'affecting', 'journey', '.'], salience=array([ 0.02434427,  0.04803366,  0.09268055,  0.31654744,  0.07632921,\n",
              "         0.17353564,  0.14552917,  0.10201892, -0.02098114]))}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "ludO8l76Geyv",
        "outputId": "900408e3-c6c9-4f3b-d49a-4107b38ea827"
      },
      "source": [
        "# Again, pretty-print output with Pandas. The SalienceMap object is just a dataclass defined using attr.s.\n",
        "pd.DataFrame(attr.asdict(lime_results['sentence']))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>salience</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>it</td>\n",
              "      <td>0.024344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'s</td>\n",
              "      <td>0.048034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>0.092681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>charming</td>\n",
              "      <td>0.316547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>and</td>\n",
              "      <td>0.076329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>often</td>\n",
              "      <td>0.173536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>affecting</td>\n",
              "      <td>0.145529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>journey</td>\n",
              "      <td>0.102019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>.</td>\n",
              "      <td>-0.020981</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      tokens  salience\n",
              "0         it  0.024344\n",
              "1         's  0.048034\n",
              "2          a  0.092681\n",
              "3   charming  0.316547\n",
              "4        and  0.076329\n",
              "5      often  0.173536\n",
              "6  affecting  0.145529\n",
              "7    journey  0.102019\n",
              "8          . -0.020981"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RosugrhIGifH",
        "outputId": "562df56b-5b07-407e-a314-5e0b23c1e006"
      },
      "source": [
        "from lit_nlp.components import gradient_maps\n",
        "ig = gradient_maps.IntegratedGradients()\n",
        "\n",
        "ig_results = ig.run(sst_data.examples[:1], sentiment_model, sst_data)[0]\n",
        "ig_results"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Found fields for integrated gradients: ['token_grad_sentence']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_grad_sentence': TokenSalience(tokens=['it', \"'\", 's', 'a', 'charming', 'and', 'often', 'affecting', 'journey', '.'], salience=array([ 0.07291325, -0.0062626 ,  0.03211318,  0.06548805,  0.36459708,\n",
              "         0.08916923,  0.10651349,  0.09290756,  0.14865497, -0.02138056],\n",
              "       dtype=float32))}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "v1ekBujJGk_I",
        "outputId": "20fb48a1-8251-4086-922a-c9a4a587515f"
      },
      "source": [
        "# Again, pretty-print output with Pandas. The SalienceMap object is just a dataclass defined using attr.s.\n",
        "pd.DataFrame(attr.asdict(ig_results['token_grad_sentence']))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>salience</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>it</td>\n",
              "      <td>0.072913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'</td>\n",
              "      <td>-0.006263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>s</td>\n",
              "      <td>0.032113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a</td>\n",
              "      <td>0.065488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>charming</td>\n",
              "      <td>0.364597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>and</td>\n",
              "      <td>0.089169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>often</td>\n",
              "      <td>0.106513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>affecting</td>\n",
              "      <td>0.092908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>journey</td>\n",
              "      <td>0.148655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>.</td>\n",
              "      <td>-0.021381</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      tokens  salience\n",
              "0         it  0.072913\n",
              "1          ' -0.006263\n",
              "2          s  0.032113\n",
              "3          a  0.065488\n",
              "4   charming  0.364597\n",
              "5        and  0.089169\n",
              "6      often  0.106513\n",
              "7  affecting  0.092908\n",
              "8    journey  0.148655\n",
              "9          . -0.021381"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRe6I5y1GlQv"
      },
      "source": [
        "## Metrics\n",
        "\n",
        "We can also compute metrics. The metrics components (via the `SimpleMetrics` API) will automatically detect compatible fields marked by the `parent` attribute - in this case, our model's `probas` field that should be scored against `label` in the input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av16xG_8Gn4y",
        "outputId": "37fa6860-e8a9-424b-dfb1-6920dee92de5"
      },
      "source": [
        "from lit_nlp.components import metrics\n",
        "classification_metrics = metrics.MulticlassMetrics()\n",
        "classification_metrics.run(sst_data.examples[:100], sentiment_model, sst_data)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label_key': 'label',\n",
              "  'metrics': {'accuracy': 0.83,\n",
              "   'f1': 0.8349514563106797,\n",
              "   'precision': 0.8431372549019608,\n",
              "   'recall': 0.8269230769230769},\n",
              "  'pred_key': 'probas'}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dKD5QKRGuOG"
      },
      "source": [
        "## Generators\n",
        "\n",
        "We can use counterfactual generators as well. Here's an example with a generator that simply scrambles words in a text segment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHAv4C03GuvU",
        "outputId": "58f05e89-9c1b-4982-8535-989eae92e58e"
      },
      "source": [
        "from lit_nlp.components import scrambler\n",
        "sc = scrambler.Scrambler()\n",
        "\n",
        "sc_in = sst_data.examples[:5]\n",
        "sc_out = sc.generate_all(sc_in, model=None, dataset=sst_data)\n",
        "# The output is a list-of-lists, generated from each original example.\n",
        "sc_out"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': '1',\n",
              "   'sentence': \"often affecting a it  journey and 's . charming\"}],\n",
              " [{'label': '0', 'sentence': 'bleak unflinchingly  desperate and'}],\n",
              " [{'label': '1',\n",
              "   'sentence': 'yet inventive that commercial to a  poised hope a us major allows . is embark career as nolan to filmmaker'}],\n",
              " [{'label': '1',\n",
              "   'sentence': \", acting the production locales austere given music , all the  's and are costumes . cinematography sound , astounding\"}],\n",
              " [{'label': '0', 'sentence': \"-- , very  's . it slow very slow\"}]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "5jCaQkpTGuzd",
        "outputId": "b89c7d7e-2379-443c-c36c-f910444aa1fc"
      },
      "source": [
        "# Format as a flat table for display, including original sentences\n",
        "import itertools\n",
        "for ex_in, exs_out in zip(sc_in, sc_out):\n",
        "  for ex_out in exs_out:\n",
        "    ex_out['original_sentence'] = ex_in['sentence']\n",
        "pd.DataFrame(itertools.chain.from_iterable(sc_out), columns=['original_sentence', 'sentence', 'label'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_sentence</th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>it 's a charming and often affecting journey .</td>\n",
              "      <td>often affecting a it  journey and 's . charming</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>unflinchingly bleak and desperate</td>\n",
              "      <td>bleak unflinchingly  desperate and</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>allows us to hope that nolan is poised to emba...</td>\n",
              "      <td>yet inventive that commercial to a  poised hop...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the acting , costumes , music , cinematography...</td>\n",
              "      <td>, acting the production locales austere given ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>it 's slow -- very , very slow .</td>\n",
              "      <td>-- , very  's . it slow very slow</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   original_sentence  ... label\n",
              "0    it 's a charming and often affecting journey .   ...     1\n",
              "1                 unflinchingly bleak and desperate   ...     0\n",
              "2  allows us to hope that nolan is poised to emba...  ...     1\n",
              "3  the acting , costumes , music , cinematography...  ...     1\n",
              "4                  it 's slow -- very , very slow .   ...     0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGZIbOy9IuBT"
      },
      "source": [
        "# Running the LIT UI\n",
        "\n",
        "Of course, you can always still use these components in the LIT UI, without leaving Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLCOC1hmGu4x"
      },
      "source": [
        "widget = notebook.LitWidget(models={'sentiment': sentiment_model}, \n",
        "                            datasets={'sst2': sst_data}, \n",
        "                            height=800)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0DKzSjtIzWd"
      },
      "source": [
        "widget.render()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}